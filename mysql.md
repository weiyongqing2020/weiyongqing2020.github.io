基础结构
Q:一条查询语句的具体执行过程是怎样的？
mysql的结构可以大致的分为：
连接器：管理连接
查询缓存：查询缓存就是查询语句和查询结构组成的key-value，如果命中则直接返回结果。				 在mysql8.0版本之后取消了查询缓存。
分析器：语法解析
优化器：优化sql语句，决定要不要使用索引，使用哪个索引，连表的策略等等。
执行器：调用存储引擎接口
存储引擎 （插件式）
//7
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/7.png)




索引
有多种用于搜索的数据结构，比如哈希表，有序数组和二叉查找树。哈希表只能等值查询，不支持范围查询，有序数组更新操作的效率低，二叉查找树对于数据量很大的情况会有很多的层数，而每层都需要读取一次磁盘，时间累加起来效率就非常低。
mysql的innodb存储引擎用B+树作为索引的数据结构。
在mysql中，数据都是以页为单位进行存储的，页的大小默认16kb，可通过设置mysql全局变量修改。
页内的记录以单链表的形式连接起来，页与页之间用双向链表的形式连接起来，页内记录通过特殊的机制，可以以二分查找来锁定记录。
innodb存储引擎中，表必须要有主键，因为要根据主键建立聚簇索引来存储数据，如果用户没有设置主键或唯一非空索引，会自动生成'row-id'的隐藏列（自增）来作为主键。主键也可以由多列组成。
索引的各个节点就是页，在非叶子节点，也就是目录页中，保存的记录是下一级的页号+下一级的页的索引列的最小值。在叶子节点以及同层的目录页中，都是按索引列由小到大顺序排列的。
索引的生成从根节点开始。
//8
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/8.png)

索引模型
聚簇索引：
在聚簇索引中，叶子节点就是完整的用户记录（包括事务id等隐藏列）。
二级索引：
二级索引的叶子节点是索引列+主键，在按该索引的查找过程中先找到其对应的主键，然后再走一遍聚簇索引，这个过程称为“回表”。
联合索引：
可以将多列组成联合索引，例如建立联合索引（c1,c2,c3），生成该索引的B+树时候就是先按照c1排序，再按照c2排序，再按照c3排序。
由此可知查询条件若没有c1，则联合索引不起作用，如果用like cl%来模糊查询，联合索引也可以起作用，这即是所谓的“最左前缀原则”。
如果查询结果只包含联合索引的列，那么可以省去“回表”操作，称为“索引覆盖”。

索引的维护：

索引极大的加快了查询的效率，但维护它也需要成本。
空间成本：每次新建一个索引都会生成一课B+树。
时间成本：为了维护索引的有序性，每次更新数据都需要操作涉及到的B+树，可能需要挪动数据，而且可能会需要申请新的数据页，也就是“页分裂”。

注：主键索引的选择：对于主键索引而言，自增主键能够显著避免“页分裂”，而且自增主键占用的空间的更小（二级索引也要保存主键），大部分场景都最好选用自增主键。也有例外，比如只有一个索引，该索引必须是唯一索引，即典型的 KV 场景，可以用业务字段做主键。

注：重建索引的方式：我们有时可能需要重建索引，因为索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。而重建索引会导致整个表重建，推荐用alter table T engine=InnoDB来重建索引。

注：造成索引失效的情况：
对查询参数使用函数会使mysql放弃走树搜索，造成索引失效。甚至查询条件是a+1=100这种不会破坏索引有序性的搜索条件也会使索引失效，如果join操作两个表的字符集不一样会隐式地使用convert函数进行转换，也会造成索引失效。
如果字段和其查询的参数一个是字符串，一个是整型，mysql会将字符串转为整型在进行比较，所以如果字段的类型是varchar，查询条件写整型，会导致全表扫描（因为要先用函数转换类型，本质上也是触发了第一条规则）。

事务
单条更新语句是隐式的事务，可以设置set autocommit=1来保证单条更新语句的自动提交。
原子性：要么同时成功，要么失败回滚，通过undolog实现
一致性：
持久性：事务提交后要保证持久化到磁盘中，通过redolog来实现
隔离性：通过隔离机制实现

事务的并发可能出现的问题：
脏写：一个事务修改了另一个事务未提交的数据。脏写是被绝对禁止的，在mysql的所有给级别中都不允许脏写。
脏读：一个事务读取了另一个事务未提交的数据。
不可重复读：一个事务多次查询同一数据得到不同的结果。
幻读：一个事务按照相同条件多次查询，结果“多出了”一些记录。

事务的隔离级别：
READ UNCOMMITTED：未提交读。可以读到其他事物未提交的数据。
READ COMMITTED：已提交读。只能读到其他事物已提交的数据。
REPEATABLE READ：可重复读。
SERIALIZABLE：串行化。顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

SQL标准中规定，针对不同的隔离级别，并发事务可以发生不同严重程度的问题，具体情况如下：
隔离级别 脏读 不可重复读 幻读
未提交读 Possible Possible Possible
已提交读 Not Possible Possible Possible
可重复读 Not Possible Not Possible Not Possible
串行化 Not Possible Not Possible Not Possible
注：mysql中在可重复读级别可以通过mvcc解决幻读问题。

mvcc的原理：
mvcc（多版本并发控制）是mysql实现读提交和可重复读的机制。

对于innodb存储引擎，聚簇索引的叶子节点除了完整的记录，还有两个关键的隐藏列：
trx_id：事务id。每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。trx_id是严格递增的。
roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然	后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。
//9
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/9.png)

在事务中每次遇到查询语句或在事务开启的时候，会创建一个ReadView（一致性视图），ReadView包含4个部分：
m_ids：创建该ReadView时，系统中活跃的（即还未提交的）事务的事务id数组。
min_trx_id：m_ids的最小值。
max_trx_id：创建该ReadView时，系统应该分配给下一个事务的id
creator_trx_id：自己的事务id
通过roll_pointer可以在undolog中找到该条记录的“版本链”，按照以下逻辑遍历该“版本链”：
如果被访问版本的trx_id等于creator_trx_id，就意味着该版本的记录是自己所做的修改，可以访问。
如果被访问版本的trx_id小于min_trx_id，表示这是之前提交的事务所做的修改，可以访问。
如果被访问版本的trx_id大于等于max_trx_id，表示这是之后提交的事务所做的修改，不可以访问。
如果被访问版本的trx_id在min_trx_id和max_trx_id之间，需要判断该版本的trx_id在不在m_ids中，在的话不可以访问，不在的话可以访问。

正是通过上述方式判断事务查询时哪些修改是已经提交过的，哪些是未提交的。

读提交与可重复读的区别就在于读提交是在每次执行查询语句就生成readview,所以再次查询时可以查到这之间已提交事务的修改。而可重复读是只在事务开始时生成一次readview，所以之后提交的事务的修改对它不可见。

注：所以undolog并不是在事务commit之后就清空，而是在没有readview用到该事务的事务id之后，再释放掉。
你可以在 information_schema 库的 innodb_trx 这个表中查询长事务：比如：
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60


注：“快照读”与“当前读”：在默认隔离级别下，单条的查询语句或在事务中的查询都是“快照读”，未提交的事务所做的修改是看不到的。而如果读的时候加共享锁（lock in share mode）或独占锁（for update），那么读到的就是当前最新版本的记录，称为“当前读”。有些修改操作需要先读取记录的值，这时候的读取也是“当前读”。
例子：

mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);



其中事务A查到的是1，事务B查到的是3


注：begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。




锁
全局锁

flush tables with read lock(FTWRL):对整个数据库实例加锁，常用于全库备份。
通过加全局锁的方式来备份，会导致业务停摆，推荐使用mysqldump，mysqldump是官方自带的逻辑备份工具，可以用mysqldump加上-single-transaction参数来备份，在导数据之前启动事务获取一致性视图，而这需要全部的数据库都是innodb存储引擎。
注：用set global readonly=true也可以实现全局只读，但不推荐使用，因为：
FTWRL在客户端发生异常断开连接时就会自动释放掉全局锁，set global readonly=true的方式不会，数据库会一直保持在只读状态，风险较高。
在有些系统中， readonly被用来做其他的逻辑，比如判断是主库还是从库。


表锁
表级别的锁有两种，一种是表锁，一种是元数据锁（metadata lock, MDL）.
表锁：通过lock tables ... read/write语句来加锁，和FTWRL一样，可以通过unlock tables来释放锁，客户端断开连接的时候也会释放锁。例如：线程a执行 lock tables  t1 read,t2 write ，那么其他线程只能读t1，t2读写都不能，线程a可以读t1,读写t2，不能访问其他表。
元数据锁：元数据锁是为了隔离MDL（数据库操作语句，即增删查改）和DDL（数据库定义语句，即修改表结构的语句）操作。当对一个表做DML操作的时候，加MDL读锁，做DDL操作的时候，加MDL写锁。读锁之间不互斥，读写或写写之间是互斥的。
注：对于操作频繁的表执行DDL操作可能会阻塞后面所有的操作！推荐在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后再通过重试命令重复这个过程。



行锁
为了事务的隔离性，写操作必须要加行锁，而且是“两阶段锁”，即在需要的时候加锁，在事务提交的时候才释放锁， 不然会发生脏写。
对于读写交错的并发事务，有两种解决方案：
写加锁，读采用MVCC
读操作和写操作都加锁
锁的种类大致可以分为共享锁和独占锁：
共享锁，英文名：Shared Locks，简称S锁。在事务要读取一条记录时，需要先获取该记录的S锁。
独占锁，也常称排他锁，英文名：Exclusive Locks，简称X锁。在事务要改动一条记录时，需要先获取该记录的X锁。

锁的兼容性：
兼容性 X S
X 不兼容 不兼容
S 不兼容 兼容

注：因为在事务结束时才会释放锁，如果事务需要锁多个行，所以尽量将可能造成锁冲突概率最大的sql语句放在事务的最后执行，这样可以减少相关记录被锁住的时间。

死锁和死锁检测：当并发系统中不同的线程出现资源的循环依赖时，这几个线程就会出现无限等待的状态，即死锁。并发事务也有可能出现死锁，有两种解决方式：
超时等待时间：可通过innodb_lock_wait_timeout设置，默认是50s，到时间后第一个被锁住的线程会退出。
死锁检测：通过innodb_deadlock_detect=on开启，默认即是开启，发现死锁后回滚死锁链中的一个事务，让其他的事务得以执行。
这两种方式的问题：
超时等待时间如果设太长业务上不能接受，设太短又不可能将正常的锁等待被当成死锁；
死锁检测比较耗费性能，当表中某行的并发事务操作特别多时，可能会因为死锁检测造成CPU占用特别高，执行事务很慢。对于这种热点数据更新导致的性能问题，解决方案主要有：
暂时关闭死锁检测，有风险。可能出现大量超时。
控制并发度：用数据库中间件实现，或者将热点行逻辑上拆分为多行。



日志
主要的日志：
redolog(重做日志)
binlog(归档日志)
undolog(回滚日志)
慢查询日志
redolog：
事务需要持久化，但不可能每次有更新操作都去刷新磁盘，因为：
可能只更新很少的记录，为此刷新整个页面太浪费。
更新可能涉及多个页面，随机IO，效率很低。
redolog很小并且记redolog是顺序IO.
所以先将更新操作记录到redolog中，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。
redolog是物理日志，记录的是将某页的某个偏移量的记录修改为某值。
redolog是固定大小，write pos 和 checkpoint之间即使可用的空间，用完就需要刷新磁盘，推进checkpoint。
redolog是存储引擎来记的日志。
//10
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/10.png)

binlog:
由server层所记，数据库通过定期的备份加上binlog，可以实现将数据库恢复为最近的备份到现在任一时间点的状态。
Q:redolog和binlog的区别？
redolog是物理日志，binlog是逻辑日志，
redolog是存储引擎生成，binlog是mysql的server层生成，在更新操作中会先更新redolog再更新binlog，并且通过两阶段提交保证这两个日志的同步。
redolog是固定大小循环使用，binlog是追加的方式，文件到了一定大小会生成新的文件继续记。
其他
buffer pool
innodb储存引擎的缓冲区
//11
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/11.png)
如图，一个控制块对应一个缓冲页，控制块的内容包括缓冲页所属的表空间，页号等。

Q：存储引擎查询的时候如何页不在buffer pool中，需要先将页加载进来，那如何判断页在不在buffer pool中呢？
存储引擎会维护一个哈希表，将页的所属的表空间和页号做为key，以次来判断效率更高。

buffer pool中的几个链表：
free-链表：处在空闲中的页。
flush-链表：做了修改需要刷新到磁盘的脏页。
lru-链表：最近最少使用链表，buffer pool的淘汰机制。

lru-链表的机制：
因为innodb引擎有预读机制，简单的说就是将查询的页附近的页也一起加到缓存中来；而且如果对一个大表做全表扫描的情况，会将大量刚查出的页放在lru-链表的头部，这严重的影响到其他查询对 Buffer Pool的使用，从而大大降低了缓存命中率。

“升级”后的lru-链表的结构如下：
//12
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/12.png)
分为冷数据区域（老年代）和热数据（新生代）区域，数据页刚加入Buffer Pool时放在冷数据区域，在1秒后如果还会被读取才会将其移动到热数据区域（因为刚加入的数据页肯定会被读取，立刻判断不准确，1秒后再判断，这个间隔由innodb_old_blocks_time参数控制）。

我们可以通过查看系统变量innodb_old_blocks_pct的值来确定old区域在LRU链表中所占的比例




explain的使用
列名 描述
id 在一个大的查询语句中每个SELECT关键字都对应一个唯一的id
select_type SELECT关键字对应的那个查询的类型
table 表名
partitions 匹配的分区信息
type 针对单表的访问方法
possible_keys 可能用到的索引
key 实际上使用的索引
key_len 实际使用到的索引长度
ref 当使用索引列等值查询时，与索引列进行等值匹配的对象信息
rows 预估的需要读取的记录条数
filtered 某个表经过搜索条件过滤后剩余记录条数的百分比
Extra 一些额外的信息
type：
const
当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是const，
eq_ref
在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是eq_ref
ref
当通过普通的二级索引列与常量进行等值匹配时来查询某个表，那么对该表的访问方法就可能是ref，最开始举过例子了，就不重复举例了。
range
如果使用索引获取某些范围区间的记录，那么就可能使用到range访问方法
index
当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是index
ALL
全表扫描

连表查询
连表查询的执行最终也是要归结为一次次的单表查询。

在连表查询中，驱动表只会查询一次，然后根据驱动表的查询结果，加上其余的查询条件一条一条去查询被驱动表， 被驱动表可能会查询多次。

被驱动表如果走全表扫描，查询时间可能会非常久，所有要尽量让被驱动表走索引查询。

内连接与外连接的区别：
内连接：驱动表中的记录如果被驱动表没有匹配，就不加入结果集
外连接：驱动表中的记录即使被驱动表没有匹配，也要加入结果集

表连接的执行种类：
被驱动表有索引Index Nested-Loop Join（INL）
Block Nested-Loop Join（BNL）
BNL是将驱动表 的数据读入线程内存 join_buffer 中，扫描被驱动表，把被驱动表中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。这种方式来提高效率。join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下驱动表 的所有数据话，策略很简单，就是分段放。

注：若被驱动表有索引，用join连表比自己在service层做逻辑效率要高。
注：不管有没有索引，都应该让小表作为驱动表。

常见问题：

Q:对字符串类型的字段加字段有哪些需要注意的点？
直接创建完整的索引，这样可能会比较占空间
创建前缀索引，节省空间，但会增加扫描次数，而且就用不到覆盖索引了。
对于前段区分度不够的字符串类型的字段，可以考虑倒序创建前缀索引。不支持范围查询。
创建hash字段索引，查询性能稳定，会增加额外的存储和计算消耗。不支持范围查询。
Q:优化器选择索引的时候主要考虑什么？
扫描的行数，是否排序，以及中间查询

Q:数据库如何大致的计算索引的总行数？
用采样统计：随机选取N个索引页，各页的记录总数/N，再乘以总页数。

Q:业务都允许的情况下，选择普通索引还是唯一索引？
选择普通索引，二者查询性能几乎没差别，但普通索引能得上chage_buffer，只记下修改，效率更高（适用于写多读少的表）。

Q:什么时候会刷新脏页？
系统空闲的时候
有缓存页需要从buffer pool中淘汰出去，而该页正好是脏页
mysql正常关闭时
redolog满了时，需要停止所有更新操作，将check point向前推进

Q:InnoDB 刷脏页的控制策略
首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：

 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 




Q:自增主键一定是连续的么？
不一定，自增主键保存在内存的全局变量中，8.0版本以后可持久化保存，自增主键在事务回滚的时候不会跟着回滚；并且在做删除操作之后再插入也是不连续的。 所以主键可能会出现"空洞" 。


Q：查询表的总行数，应该用count(*)，count(1),还是count(主键)？
首先innodb为什么不能像myisam一样，记录下表的总行数？
因为mvcc机制，每个会话能看到的行数是不一样的。
用count(*)，因为innodb对count(*)做过特殊的优化，不会读出数据，只计算行数，但不能跟where子句，不然这个优化将失效。



Q:如果只查询一行记录，执行却特别慢，可能有哪些原因？
等mdl锁
等行锁
可以先执行一下 show processlist 命令，看看当前语句处于什么状态。
//13
![](https://notebook-pictures.obs.cn-north-4.myhuaweicloud.com/13.png)


